{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOg09VGXMr2q2L/GA/Bj0qx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dchirosca/airbnb-insights/blob/main/script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k23hBjlEbBXY"
      },
      "outputs": [],
      "source": [
        "install.packages(\"dplyr\") # for data pre-processing\n",
        "install.packages(\"tidyr\") # for data pre-processing\n",
        "install.packages(\"rlang\") # for data pre-processing\n",
        "install.packages(\"caret\")\n",
        "install.packages(\"randomForest\")\n",
        "install.packages(\"e1071\")\n",
        "\n",
        "library(dplyr) # for data pre-processing\n",
        "library(tidyr) # for data pre-processing\n",
        "library(rlang) # for data pre-processing\n",
        "library(caret)\n",
        "library(randomForest)\n",
        "library(e1071)\n",
        "options(scipen = 99)\n",
        "\n",
        "dt<-read.csv(\"listings.csv\")\n",
        "\n",
        "# DATA PRE-PROCESSING -------------------------------------\n",
        "\n",
        "# First, any column with information that will not be used in creating a model will be eliminated from the dataset\n",
        "\n",
        "dt<-dt[, !names(dt) %in% c(\"listing_url\",\n",
        "                           \"scrape_id\",\n",
        "                           \"last_scraped\",\n",
        "                           \"source\",\n",
        "                           \"description\",\n",
        "                           \"picture_url\",\n",
        "                           \"host_url\",\n",
        "                           \"host_name\",\n",
        "                           \"host_location\",\n",
        "                           \"host_thumbnail_url\",\n",
        "                           \"host_picture_url\",\n",
        "                           \"host_neighbourhood\",\n",
        "                           \"host_listings_count\",\n",
        "                           \"neighborhood_overview\",\n",
        "                           \"neighbourhood\",\n",
        "                           \"neighbourhood_group_cleansed\",\n",
        "                           \"latitude\",\n",
        "                           \"longitude\",\n",
        "                           \"calendar_updated\",\n",
        "                           \"license\",\n",
        "                           \"calculated_host_listings_count\",\n",
        "                           \"calculated_host_listins_count_entire_homes\",\n",
        "                           \"calculated_host_listings_count_private_rooms\",\n",
        "                           \"calculated_host_listings_count_shared_rooms\",\n",
        "                           \"minimum_minimum_nights\",\n",
        "                           \"maximum_minimum_nights\",\n",
        "                           \"minimum_maximum_nights\",\n",
        "                           \"maximum_maximum_nights\",\n",
        "                           \"minimum_nights_avg_ntm\",\n",
        "                           \"maximum_nights_avg_ntm\",\n",
        "                           \"has_availability\",\n",
        "                           \"calendar_last_scraped\",\n",
        "                           \"number_of_reviews_ltm\",\n",
        "                           \"number_of_review_l30d\",\n",
        "                           \"calculated_host_listings_count_entire_homes\")]\n",
        "\n",
        "# Aiming to check the following steps to prepare the data for modelling:\n",
        "\n",
        "\n",
        "# Remove duplicates -------------------------------------------------------\n",
        "\n",
        "dt<- dt %>% distinct() # no duplicates have been identified\n",
        "\n",
        "\n",
        "# Fix structural errors ---------------------------------------------------\n",
        "\n",
        "# Correcting naming conventions\n",
        "dt$host_is_superhost<-ifelse(dt$host_is_superhost == 't', 1, 0)\n",
        "dt$host_has_profile_pic<-ifelse(dt$host_has_profile_pic == 't', 1, 0)\n",
        "dt$host_identity_verified<-ifelse(dt$host_identity_verified == 't', 1, 0)\n",
        "dt$instant_bookable<-ifelse(dt$instant_bookable == 't', 1, 0)\n",
        "dt$host_response_time<-ifelse(dt$host_response_time == 'N/A', NA, dt$host_response_time)\n",
        "dt$host_response_rate<-ifelse(dt$host_response_rate == 'N/A', NA, dt$host_response_rate)\n",
        "dt$host_acceptance_rate<-ifelse(dt$host_acceptance_rate == 'N/A', NA, dt$host_acceptance_rate)\n",
        "# Replacing a missing host description with NA for now\n",
        "dt<-dt %>% mutate(host_about = replace(host_about, host_about == \"\", NA))\n",
        "# Transforming response and acceptance rate into appropriate formats\n",
        "dt$host_response_rate<-gsub(\"%\", \"\", dt$host_response_rate)\n",
        "dt$host_acceptance_rate<-gsub(\"%\", \"\", dt$host_acceptance_rate)\n",
        "dt$host_response_rate<-as.numeric(dt$host_response_rate)\n",
        "dt$host_acceptance_rate<-as.numeric(dt$host_acceptance_rate)\n",
        "# Transforming the price variable in numeric type\n",
        "for(i in 1:dim(dt)[1]){\n",
        "  dt$price[i]<-as.numeric(substr(dt$price[i], start = 2, stop = nchar(dt$price[i])))\n",
        "}\n",
        "# Extracting only a name for the unit, given that the name column contains more information that is otherwise captured in other columns\n",
        "# Extracting the number of bedrooms, where this information is available\n",
        "unit_name<-c()\n",
        "for(i in 1:dim(dt)[1]){\n",
        "  unit_name[i]<-strsplit(dt$name[i], split = \"Â·\")[[1]][1]\n",
        "  if(grepl(\"bedroom\", dt$name[i]) == TRUE){\n",
        "    dt$bedrooms[i]<-substr(dt$name[i],\n",
        "                           start = regexpr(\"bedroom\", dt$name[i])-2,\n",
        "                           stop = regexpr(\"bedroom\", dt$name[i])-2)\n",
        "  }\n",
        "}\n",
        "dt<-cbind(dt, unit_name)\n",
        "dt<-dt[, !names(dt) == \"name\"]\n",
        "# Extracting the number of baths\n",
        "dt$bathrooms<-as.numeric(gsub(\"[^0-9]\", \"\", dt$bathrooms_text)) # this will extract all numbers from text column, but without the decimal point\n",
        "dt$bathrooms<-ifelse(dt$bathrooms>10, dt$bathrooms/10, dt$bathrooms) # correcting the number of baths by dividing by 10 all values greater than 10, since a property can't have more than 10 bathrooms\n",
        "dt$bathrooms_text<-gsub(\"[0-9]\", \"\", dt$bathrooms_text) # extracting the type of bath\n",
        "# correcting the extracted type format\n",
        "dt$bathrooms_text<-substr(dt$bathrooms_text, 2, nchar(dt$bathrooms_text))\n",
        "dt$bathrooms_text<-trimws(dt$bathrooms_text, which = \"left\")\n",
        "dt<-dt %>% mutate(bathrooms_text = replace(bathrooms_text, bathrooms_text == \"\", NA)) # replacing the missing values with NA for now\n",
        "# Extracting the number of host verifications & amenities available to the guests\n",
        "no_host_verifications<-c()\n",
        "no_amenities<-c()\n",
        "for(i in 1:dim(dt)[1]){\n",
        "  no_host_verifications[i]<-length(strsplit(dt$host_verifications[i], split = \",\")[[1]])\n",
        "  no_amenities[i]<-length(strsplit(dt$amenities[i], split = \",\")[[1]])\n",
        "}\n",
        "dt<-cbind(dt, no_host_verifications, no_amenities)\n",
        "dt<-dt[, !names(dt) %in% c(\"host_verifications\", \"amenities\")]\n",
        "# Dealing with columns that contain dates and transforming them into numeric variables\n",
        "class(dt$host_since) # the date is currently stored as character\n",
        "dt$host_since<-as.Date(dt$host_since, format = \"%Y-%m-%d\")\n",
        "host_seniority<-as.numeric(difftime(time1 = Sys.Date(),\n",
        "                                    time2 = dt$host_since,\n",
        "                                    units = \"days\")) # days since the host has registered as such in the airbnb system\n",
        "dt<-data.frame(dt, host_seniority)\n",
        "dt$first_review<-as.Date(dt$first_review, format = \"%Y-%m-%d\")\n",
        "dt$last_review<-as.Date(dt$last_review, format = \"%Y-%m-%d\")\n",
        "days_fr<-as.numeric(difftime(time1 = Sys.Date(),\n",
        "                                    time2 = dt$first_review,\n",
        "                                    units = \"days\")) # days since the first review\n",
        "days_lr<-as.numeric(difftime(time1 = Sys.Date(),\n",
        "                             time2 = dt$last_review,\n",
        "                             units = \"days\")) # days since the last review\n",
        "dt<-cbind(dt, days_fr, days_lr)\n",
        "dt<-dt[, !names(dt) %in% c(\"host_since\", \"first_review\", \"last_review\")]\n",
        "\n",
        "# Adding additional variable to measure neighborhood safety\n",
        "n_dt<-read.csv(file = \"n_dt.csv\")\n",
        "dt<-merge(x = dt, y = n_dt, by.x = \"neighbourhood_cleansed\", by.y = \"neighborhood\", all.x = TRUE) # introduced the Human Development Index for each neighborhood to measure area safety\n",
        "dt<-dt[, !names(dt) == \"neighbourhood_cleansed\"]\n",
        "\n",
        "# Introducing a variable that evaluates if a property is new or existing\n",
        "listing_type<-ifelse(is.na(dt$review_scores_rating) == TRUE, \"new\", \"existing\")\n",
        "dt<-cbind(dt, listing_type)\n",
        "\n",
        "# Introducing new features related to the host description\n",
        "description_no_words<-c()\n",
        "for(i in 1:dim(dt)[1]){\n",
        "  if(is.na(dt$host_about[i]) == TRUE){\n",
        "    description_no_words[i]<-0\n",
        "  } else{\n",
        "    description_no_words[i]<-length(strsplit(dt$host_about[i], \" \")[[1]])\n",
        "  }\n",
        "}\n",
        "dt<-cbind(dt, description_no_words)\n",
        "\n",
        "# Transforming availability in a more suitable format\n",
        "dt$availability_30<-round(dt$availability_30/30,4)\n",
        "dt$availability_60<-round(dt$availability_60/60,4)\n",
        "dt$availability_90<-round(dt$availability_90/90,4)\n",
        "dt$availability_365<-round(dt$availability_365/365,4)\n",
        "\n",
        "# Dropping any last set of columns that cannot be used in the analysis\n",
        "dt<-dt[, !names(dt) %in% c(\"id\",\n",
        "                           \"host_id\",\n",
        "                           \"host_about\",\n",
        "                           \"number_of_reviews_l30d\",\n",
        "                           \"review_scores_accuracy\",\n",
        "                           \"review_scores_cleanliness\",\n",
        "                           \"review_scores_checkin\",\n",
        "                           \"review_scores_communication\",\n",
        "                           \"review_scores_location\",\n",
        "                           \"review_scores_value\",\n",
        "                           \"unit_name\",\n",
        "                           \"property_type\")]\n",
        "\n",
        "dt<-dt %>% mutate_at(vars(host_response_rate,\n",
        "                 host_acceptance_rate,\n",
        "                 host_total_listings_count,\n",
        "                 accommodates,\n",
        "                 bathrooms,\n",
        "                 bedrooms,\n",
        "                 beds,\n",
        "                 price,\n",
        "                 minimum_nights,\n",
        "                 maximum_nights,\n",
        "                 availability_30,\n",
        "                 availability_60,\n",
        "                 availability_90,\n",
        "                 availability_365,\n",
        "                 number_of_reviews,\n",
        "                 review_scores_rating,\n",
        "                 reviews_per_month,\n",
        "                 no_host_verifications,\n",
        "                 no_amenities,\n",
        "                 host_seniority,\n",
        "                 days_fr,\n",
        "                 days_lr,\n",
        "                 HI_index,\n",
        "                 description_no_words), as.numeric)\n",
        "\n",
        "# Dealing with missing values ---------------------------------------------\n",
        "\n",
        "# Rows that do not have any value for the variables that describe the property, will be eliminated\n",
        "print(paste0(\"The initial number of rows is \", dim(dt)[1])) # 39627\n",
        "# Separating the new properties from the existing ones\n",
        "df<-dt %>% filter(listing_type == \"new\")\n",
        "dt<-dt %>% filter(listing_type == \"existing\") # keeping only the existing properties who had at least one guest\n",
        "dt<-dt %>% drop_na()\n",
        "dt<-dt[, !names(dt) == \"listing_type\"]\n",
        "\n",
        "# Data encoding -----------------------------------------------------------\n",
        "\n",
        "# Transforming the character variables in categorial variables\n",
        "dt$host_response_time<-as.factor(dt$host_response_time)\n",
        "dt$room_type<-as.factor(dt$room_type)\n",
        "dt$bathrooms_text<-as.factor(dt$bathrooms_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random forest with grid search**\n",
        "\n",
        "The principle of grid search is quite simple: the model will be evaluated over all the combinations passed to the function, using cross-validation.\n",
        "For this analysis, we will implement random search - this method will not evaluate all the combinations of hyperparameters in the searching space all at once, but it will randomly choose combinations at every iteration. This method has the great advantage of lower computational cost compared to the original grid search method.\n",
        "We will follow these steps:\n",
        "*   Find the best number of mtry\n",
        "*   Find the best number of maxnodes\n",
        "*   Find the best number of ntrees\n",
        "*   Evaluate the optimal model\n",
        "\n",
        "Afterwards, we will also vizualize the importance of the variables.\n",
        "The best number of mtry, maxnodes and ntrees will be chosen by minimizing the RMSE generated by the model.\n",
        "For the evaluation of the model, we will use a **K-fold cross validation**, which will be implemented using the trainControl() function from R. For this function, we will use:\n",
        "*   **method** = \"cv\"; this is the method used to resample the dataset and is referring to cross-validation. In cross-validation, the dataset is randomly divided into k subsets (also called folds). For each iteration, one subset is kept as the validation data and the remaining k-1 are used as training data. K results will be obtained and they will be averaged to produce one single estimation.\n",
        "*   **number** = n; the number of folds to create. We will choose a default number of 10 folds that will offer a good balance between computational efficiency and reliable estimates created by the model\n",
        "*   **search** = \"grid\" to use the search grid method\n",
        "\n",
        "The randomForest algorithm has the following structure in R:\n",
        "*RandomForest(formula, ntree, mtry, maxnodes)*, where:\n",
        "*   **formula**: the formula of the fitted model which will be review_scores_rating~. to use review_scores_rating as a function of all the features included in the dataset\n",
        "*   **ntree**: the number of trees in the forest; generally, the more trees, the better the model performance, but the improvements will plateau after a certain point. Usually, a number between 100 and 1000 is used to train random forest models\n",
        "*   **mtry**: the number of variable candidates draw to feed the algorithm\n",
        "*   **maxnodes**: the maximum amount of terminal nodes in the forest; large numbers of terminal trees tend to increase the model complexity, but also might lead to overfitting\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BtwTa_rl0xXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest -----------------------------------------------------------\n",
        "\n",
        "# Searching for the best mtry with grid search\n",
        "set.seed(1234)\n",
        "tuneGrid<-expand.grid(.mtry = c(10: 20)) # starting with one-third of the total number of variables\n",
        "rf_default<-train(review_scores_rating~.,\n",
        "                  data = dt,\n",
        "                  method = \"rf\",\n",
        "                  metric = \"rmse\",\n",
        "                  trControl = trainControl(method = \"cv\",\n",
        "                                             number = 10,\n",
        "                                             search = \"grid\"),\n",
        "                  tuneGrid = tuneGrid,\n",
        "                  importance = TRUE)\n",
        "print(rf_default)\n",
        "\n",
        "rf_default$bestTune$mtry # mtry = 11\n",
        "min(rf_default$results$RMSE) # the lowest RMSE = 0.206375387857852\n",
        "\n",
        "best_mtry<-rf_default$bestTune$mtry\n",
        "best_mtry\n",
        "\n",
        "# Searching for the best maxnodes\n",
        "store_maxnode <- list()\n",
        "tuneGrid <- expand.grid(.mtry = best_mtry)\n",
        "for (maxnodes in c(5:30)) {\n",
        "    set.seed(1234)\n",
        "    rf_maxnode <- train(review_scores_rating~.,\n",
        "        data = dt,\n",
        "        method = \"rf\",\n",
        "        metric = \"RMSE\",\n",
        "        tuneGrid = tuneGrid,\n",
        "        trControl = trainControl(method = \"cv\",\n",
        "                                             number = 10,\n",
        "                                             search = \"grid\"),\n",
        "        importance = TRUE,\n",
        "        nodesize = 14,\n",
        "        maxnodes = maxnodes,\n",
        "        ntree = 300)\n",
        "    key<-toString(maxnodes)\n",
        "    store_maxnode[[key]] <- rf_maxnode\n",
        "}\n",
        "results_node <- resamples(store_maxnode)\n",
        "summary(results_node) # maxnodes = 29 has the lowest RMSE value of 0.2106723, so we will continue with it\n",
        "\n",
        "# Searching the best ntrees\n",
        "store_maxtrees <- list()\n",
        "tuneGrid <- expand.grid(.mtry = best_mtry)\n",
        "for (ntree in c(250, 300, 350, 400, 450, 500, 550, 600, 800, 1000, 2000)) {\n",
        "    set.seed(1234)\n",
        "    rf_maxtrees <- train(review_scores_rating~.,\n",
        "        data = dt,\n",
        "        method = \"rf\",\n",
        "        metric = \"RMSE\",\n",
        "        tuneGrid = tuneGrid,\n",
        "        trControl = trainControl(method = \"cv\",\n",
        "                                             number = 10,\n",
        "                                             search = \"grid\"),\n",
        "        importance = TRUE,\n",
        "        nodesize = 14,\n",
        "        maxnodes = 29,\n",
        "        ntree = ntree)\n",
        "    key <- toString(ntree)\n",
        "    store_maxtrees[[key]] <- rf_maxtrees\n",
        "}\n",
        "results_tree <- resamples(store_maxtrees)\n",
        "summary(results_tree) # will train a model with ntrees = 400 which returns a RMSE of 0.2106102\n",
        "\n",
        "# Creating the first model\n",
        "set.seed(1234)\n",
        "tuneGrid<-expand.grid(.mtry = best_mtry)\n",
        "fit_rf<-randomForest(review_scores_rating~.,\n",
        "    data = dt,\n",
        "    method = \"rf\",\n",
        "    metric = \"RMSE\",\n",
        "    tuneGrid = tuneGrid,\n",
        "    trControl = trainControl(method = \"cv\",\n",
        "                                             number = 10,\n",
        "                                             search = \"grid\"),\n",
        "    importance = TRUE,\n",
        "    nodesize = 14,\n",
        "    ntree = 400,\n",
        "    maxnodes = 29)\n",
        "summary(fit_rf)\n",
        "sqrt(mean(fit_rf$mse))\n",
        "\n",
        "install.packages(\"ggRandomForests\")\n",
        "library(ggRandomForests)\n",
        "error_plot<-gg_error(fit_rf)\n",
        "plot(error_plot)\n",
        "\n",
        "# Vizualizing variable importance\n",
        "varImpPlot(fit_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "KBjVm9mV5_b6",
        "outputId": "0f04ea70-e1c7-4d3f-b2bd-17a598e67054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in gg_cle(fit_rf, pred.var = \"HI_index\"): could not find function \"gg_cle\"\n",
          "traceback": [
            "Error in gg_cle(fit_rf, pred.var = \"HI_index\"): could not find function \"gg_cle\"\nTraceback:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost**\n",
        "\n",
        "To get the dataset ready to be fed into the xgboost function, we needed to:\n",
        "\n",
        "Remove information about the target variable from the\n",
        "\n",
        "*   Remove information about the target variable from the training data\n",
        "*   Reduce the redudant information (*done in the first part of the script*)\n",
        "*   Convert categorial information to a numeric format\n",
        "*   Convert the dataframes into Dmatrixes"
      ],
      "metadata": {
        "id": "RKAxtxvmz02H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost -----------------------------------------------------------\n",
        "install.packages(\"xgboost\")\n",
        "library(xgboost)\n",
        "library(plyr)\n",
        "\n",
        "# Preparing the data for xgboost implementation\n",
        "# Convert categorical information to a numeric format\n",
        "dt$host_response_time<-as.character(dt$host_response_time)\n",
        "dt$host_response_time<-mapvalues(dt$host_response_time,\n",
        "                              from = unique(dt$host_response_time),\n",
        "                              to = c(1:length(unique(dt$host_response_time))))\n",
        "dt$host_response_time<-as.numeric(dt$host_response_time)\n",
        "dt$room_type<-as.character(dt$room_type)\n",
        "dt$room_type<-mapvalues(dt$room_type,\n",
        "                              from = unique(dt$room_type),\n",
        "                              to = c(1:length(unique(dt$room_type))))\n",
        "dt$room_type<-as.numeric(dt$room_type)\n",
        "dt$bathrooms_text<-as.character(dt$bathrooms_text)\n",
        "dt$bathrooms_text<-mapvalues(dt$bathrooms_text,\n",
        "                              from = unique(dt$bathrooms_text),\n",
        "                              to = c(1:length(unique(dt$bathrooms_text))))\n",
        "dt$bathrooms_text<-as.numeric(dt$bathrooms_text)\n",
        "\n",
        "# Spliting dataset into trainging and testing subsets\n",
        "set.seed(1234)\n",
        "splitIndex<-createDataPartition(dt$review_scores_rating, p = 0.75, list = FALSE) # splitting the dataset in 75-25 training and test\n",
        "train_data<-dt[splitIndex,]\n",
        "test_data<-dt[-splitIndex,]\n",
        "\n",
        "# Separate features and labels\n",
        "train_labesl<-train_data$review_scores_rating\n",
        "train_data<-train_data[, -which(names(train_data) == \"review_scores_rating\")]\n",
        "\n",
        "test_labels<-test_data$review_scores_rating\n",
        "test_data<-test_data[, -which(names(test_data) == \"review_scores_rating\")]\n",
        "\n",
        "# Convert the cleaned dataframe to a Dmatrix\n",
        "dtrain<-xgb.DMatrix(data = as.matrix(train_data), label = train_labels)\n",
        "dtest<-xgb.DMatrix(data = as.matrix(test_data), label = test_labels)"
      ],
      "metadata": {
        "id": "2gjOKcGe0cUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the XGBoost Model**\n",
        "\n",
        "We will first train one model and then work on optimizing the parameters.\n",
        "Since our business problem is of regression type, there are multiple options to choose from:\n",
        "*   reg:squarederror (Mean Squared Error) - this is used when the dataset has a Gaussian error distribution and is the most common choice for regression problems\n",
        "*   reg:squaredlogerror (Mean Squared Logarithmic Error) - this is used when the target variable is positive and it is desired to penalize underestimates more than overestimates; this type of regression is particularly useful when dealing with growth rates\n",
        "*   reg:absoluteerror (Mean Absolute Error) - this is especially used when the data has outliers or non-normal error distribution; this type of regression will treat all the errors the same regardless of their size\n",
        "*   reg:quantileerror (Quantile Loss) - this type is used when it is desired that a certain percentile of the distribution of the target variable will also be predicted, aside from the mean\n",
        "\n",
        "Due to the presence of outliers and the target variable being only positive, we will choose squaredlogerror\n",
        "\n",
        "We will start with a learning rate (eta) of 0.3, a maximum depth of a tree of 6\n",
        "\n"
      ],
      "metadata": {
        "id": "U4CU-SxXJLAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params<-list(\n",
        "  objective = \"reg:squaredlogerror\",\n",
        "  eta = 0.3,\n",
        "  max_depth = 6\n",
        ")\n",
        "\n",
        "set.seed(1234)  # for reproducibility\n",
        "xgb_model<-xgb.train(params, dtrain, nrounds = 1000)\n",
        "preds<-predict(xgb_model, dtest)\n",
        "preds\n",
        "rmse<-sqrt(mean((preds - test_labels)^2))\n",
        "print(rmse) # we obtain a RMSE of 0.2359304, which currently is higher than the value from the randomForest model\n",
        "plot(test_labels, preds, xlim = c(4,5), ylim = c(4,5), xlab = \"observed\", ylab = \"predicted\")\n",
        "\n",
        "# Further, we will hyperparameter tune the xgboost model\n",
        "\n",
        "# creating a grid of hyperparameters\n",
        "nrounds<-seq(from = 100, to = 1000, by = 100)\n",
        "eta<-c(0.05, 0.1, 0.3, 0.5)\n",
        "max_depth<-c(6, 8, 10)\n",
        "gamma<-c(0, 0.1, 0.2)\n",
        "\n",
        "rmse_values<-c()\n",
        "model_params<-c()\n",
        "for(i in 1:length(nrounds)){\n",
        "  for(j in 1:length(eta)){\n",
        "    for(m in 1:length(max_depth)){\n",
        "      for(n in 1:length(gamma)){\n",
        "        params<-list(objective = \"reg:squaredlogerror\",\n",
        "                      eta = eta[j],\n",
        "                      max_depth = max_depth[m],\n",
        "                      gamma = gamma[n]\n",
        "                    )\n",
        "        set.seed(1234)  # for reproducibility\n",
        "        xgb_model<-xgb.train(params, dtrain, nrounds = nrounds[i])\n",
        "        preds<-predict(xgb_model, dtest)\n",
        "        rmse<-sqrt(mean((preds - test_labels)^2))\n",
        "        rmse_values<-c(rmse_values, rmse)\n",
        "        model_params<-c(model_params, paste0(\"nrounds\", nrounds[i], \"eta\", eta[j], \"max_depth\", max_depth[m], \"gamma\", gamma[n]))\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "xgb_models<-data.frame(model_params, rmse_values)\n",
        "min(xgb_models$rmse_values) # RMSE = 0.2180775\n",
        "xgb_models[which.min(xgb_models$rmse_values),] # nrounds = 200, eta = 0.05, max_depth = 8, gamma = 0\n",
        "\n",
        "params<-list(\n",
        "  objective = \"reg:squaredlogerror\",\n",
        "  eta = 0.05,\n",
        "  max_depth = 8\n",
        ")\n",
        "set.seed(1234)  # for reproducibility\n",
        "opt_xgb_model<-xgb.train(params, dtrain, nrounds = 200)\n",
        "preds<-predict(opt_xgb_model, dtest)\n",
        "rmse<-sqrt(mean((preds - test_labels)^2))\n",
        "print(rmse) # we obtain a RMSE of 0.2180775, which currently is higher than the value from the randomForest model\n",
        "plot(test_labels, preds, xlim = c(4,5), ylim = c(4,5), xlab = \"observed\", ylab = \"predicted\")\n",
        "\n",
        "# Vizualizing variable importance\n",
        "importance_matrix<-xgb.importance(feature_names = colnames(train_data), model = opt_xgb_model)\n",
        "xgb.plot.importance(importance_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Lr7ZzNTUJ9S8",
        "outputId": "4a86a011-a579-4ba7-e51e-0e3234844cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "360"
            ],
            "text/markdown": "360",
            "text/latex": "360",
            "text/plain": [
              "[1] 360"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}